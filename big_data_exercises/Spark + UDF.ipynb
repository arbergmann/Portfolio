{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark + Yelp Exercise\n",
    "Spark exercise leveraging the Yelp Academic Dataset to improve familiarity with PySpark and work on basics of Spark UDFs.\n",
    "\n",
    "`%%time` functions included, but results may vary by operating system configuration.\n",
    "_________________________\n",
    "\n",
    "First, spin up a Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test1') \\\n",
    "    .getOrCreate() \n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets (this will take a few minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# business = spark.read.json('../assets/yelp_academic/yelp_academic_dataset_business.json.gz')\n",
    "# checkin = spark.read.json('../assets/yelp_academic/yelp_academic_dataset_checkin.json.gz')\n",
    "# review = spark.read.json('../assets/yelp_academic/yelp_academic_dataset_review.json.gz')\n",
    "# tip = spark.read.json('../assets/yelp_academic/yelp_academic_dataset_tip.json.gz')\n",
    "# user = spark.read.json('../assets/yelp_academic/yelp_academic_dataset_user.json.gz')\n",
    "\n",
    "business = spark.read.json('../non_auto_assignments/data/yelp_academic/yelp_academic_dataset_business.json.gz')\n",
    "checkin = spark.read.json('../non_auto_assignments/data/yelp_academic/yelp_academic_dataset_checkin.json.gz')\n",
    "review = spark.read.json('../non_auto_assignments/data/yelp_academic/yelp_academic_dataset_review.json.gz')\n",
    "tip = spark.read.json('../non_auto_assignments/data/yelp_academic/yelp_academic_dataset_tip.json.gz')\n",
    "user = spark.read.json('../non_auto_assignments/data/yelp_academic/yelp_academic_dataset_user.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many users have received more than 5000 \"cool\" compliments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- compliment_cool: long (nullable = true)\n",
      " |-- compliment_cute: long (nullable = true)\n",
      " |-- compliment_funny: long (nullable = true)\n",
      " |-- compliment_hot: long (nullable = true)\n",
      " |-- compliment_list: long (nullable = true)\n",
      " |-- compliment_more: long (nullable = true)\n",
      " |-- compliment_note: long (nullable = true)\n",
      " |-- compliment_photos: long (nullable = true)\n",
      " |-- compliment_plain: long (nullable = true)\n",
      " |-- compliment_profile: long (nullable = true)\n",
      " |-- compliment_writer: long (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- elite: string (nullable = true)\n",
      " |-- fans: long (nullable = true)\n",
      " |-- friends: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- yelping_since: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = user.filter(user['compliment_cool'] > 5000).count()\n",
    "res1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the top 10 most complimented businesses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 254 ms, sys: 39 ms, total: 293 ms\n",
      "Wall time: 6.08 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>compliment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Peaceful Farewell</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st Pet Veterinary Centers</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Department of Motor Vehicles</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baladie Café</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moko Ramen Bar</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr. William M. Jacobsen MD</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bomboba</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Southwest Airlines</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Burgh'ers Brewing</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pineapple Park</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  compliment_count\n",
       "0           A Peaceful Farewell                15\n",
       "1    1st Pet Veterinary Centers                12\n",
       "2  Department of Motor Vehicles                11\n",
       "3                  Baladie Café                 9\n",
       "4                Moko Ramen Bar                 8\n",
       "5    Dr. William M. Jacobsen MD                 7\n",
       "6                       Bomboba                 7\n",
       "7            Southwest Airlines                 7\n",
       "8             Burgh'ers Brewing                 7\n",
       "9                Pineapple Park                 6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Reduce the tip dataset to the top 10 most complimented\n",
    "top_10 = tip.sort(col(\"compliment_count\").desc()).head(10)\n",
    "top_10 = spark.createDataFrame(top_10)\n",
    "\n",
    "# Join the two on a left join (just top 10), using the business id, and return the name and compliment count\n",
    "res2 = top_10.join(business, top_10.business_id == business.business_id, how='left') \\\n",
    "           .select(business.name, top_10.compliment_count)\n",
    "\n",
    "# Show DataFrame\n",
    "#q2.show()\n",
    "res2.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the top number of compliments is only 15. I would have thought with a large dataset like this it would have yielded at least one or two with some outlier amount, especially with large companies included such as Southwest Airlines. Then again...typically the loudest (and angriest) voices are the ones posted. Just an interesting observation!\n",
    "\n",
    "#### What are the top 10 most useful reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.07 ms, sys: 10.1 ms, total: 14.2 ms\n",
      "Wall time: 59 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1241</td>\n",
       "      <td>Dinner for 1.\\n\\n- Preface\\nI went to Amy's Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1122</td>\n",
       "      <td>In retrospect, I should have known better than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>970</td>\n",
       "      <td>This restaurant is horrible. \\n\\nFirst off the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>846</td>\n",
       "      <td>This is the second time I've been here and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>808</td>\n",
       "      <td>I actually suspect that a lot of people who ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>781</td>\n",
       "      <td>\"scary that people like this can own a biz; sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>694</td>\n",
       "      <td>I really wanted to like this place.\\nIt's clea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>668</td>\n",
       "      <td>A few years ago after attending a movie across...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>650</td>\n",
       "      <td>I'd put zero stars if it was an option- the fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>578</td>\n",
       "      <td>We were very disappointed with this restaurant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   useful                                               text\n",
       "0    1241  Dinner for 1.\\n\\n- Preface\\nI went to Amy's Ba...\n",
       "1    1122  In retrospect, I should have known better than...\n",
       "2     970  This restaurant is horrible. \\n\\nFirst off the...\n",
       "3     846  This is the second time I've been here and the...\n",
       "4     808  I actually suspect that a lot of people who ha...\n",
       "5     781  \"scary that people like this can own a biz; sa...\n",
       "6     694  I really wanted to like this place.\\nIt's clea...\n",
       "7     668  A few years ago after attending a movie across...\n",
       "8     650  I'd put zero stars if it was an option- the fo...\n",
       "9     578  We were very disappointed with this restaurant..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Sort dataset by most useful, descending, and take top 10\n",
    "most_useful = review.sort(col(\"useful\").desc()).head(10)\n",
    "\n",
    "# Put back into dataframe form\n",
    "most_useful = spark.createDataFrame(most_useful)\n",
    "\n",
    "# Select desired columns (useful ranking, and text of the review)\n",
    "most_useful = most_useful.select(most_useful.useful, most_useful.text)\n",
    "\n",
    "# Show dataframe\n",
    "#most_useful.show()\n",
    "most_useful.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the midpoint of this exercise, I saw that most were lower-starred ratings. I found that interesting as it would appear that unfavorable reviews are often found to be more helpful - realistically, because they are probably more honest about what is wrong instead of everything being as someone expected. Funnily enough, after further research, Amy's Baking Company was featured on Kitchen Nightmares - so the public exposure may have resulted in more reviews.\n",
    "\n",
    "#### Top 10 most useful <i>positive</i> reviews?\n",
    "- 5-star review considered \"positive\"\n",
    "- top ten 5 star reviews by order, did not consider ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 ms, sys: 4.62 ms, total: 15.8 ms\n",
      "Wall time: 54.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>358</td>\n",
       "      <td>The Wynn Hotel. One word. Opulent. \\n\\nWynn, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>278</td>\n",
       "      <td>Wayne does a fantastic Job, always on time, my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241</td>\n",
       "      <td>This is one of the most interesting classic lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215</td>\n",
       "      <td>Wenn man auf dem Strip zu Fuß unterwegs ist, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>215</td>\n",
       "      <td>I stopped by Echo and Rig during lunch time on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>210</td>\n",
       "      <td>After spending a bunch of money on lunches and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>208</td>\n",
       "      <td>Why spend hundreds of dollars bribing doucheba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>207</td>\n",
       "      <td>Unser eher bescheidenes Motel war in der Nähe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>207</td>\n",
       "      <td>Auf unserer Rundreise haben wir häufig die Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>203</td>\n",
       "      <td>Auf unserer Casino Besichtigungstour sind wir ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   useful                                               text\n",
       "0     358  The Wynn Hotel. One word. Opulent. \\n\\nWynn, i...\n",
       "1     278  Wayne does a fantastic Job, always on time, my...\n",
       "2     241  This is one of the most interesting classic lo...\n",
       "3     215  Wenn man auf dem Strip zu Fuß unterwegs ist, s...\n",
       "4     215  I stopped by Echo and Rig during lunch time on...\n",
       "5     210  After spending a bunch of money on lunches and...\n",
       "6     208  Why spend hundreds of dollars bribing doucheba...\n",
       "7     207  Unser eher bescheidenes Motel war in der Nähe ...\n",
       "8     207  Auf unserer Rundreise haben wir häufig die Res...\n",
       "9     203  Auf unserer Casino Besichtigungstour sind wir ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Sort dataset by most useful, descending, and take top 10\n",
    "most_useful_pos = review['stars','text','useful'].filter(review['stars'] == 5) \\\n",
    "                                                 .sort(col(\"useful\").desc()).head(10)\n",
    "\n",
    "# Put back into dataframe form\n",
    "most_useful_pos = spark.createDataFrame(most_useful_pos)\n",
    "\n",
    "# Select desired columns (useful ranking, and text of the review)\n",
    "most_useful_pos = most_useful_pos.select(most_useful_pos.useful, most_useful_pos.text)\n",
    "\n",
    "# Show dataframe\n",
    "#most_useful.show()\n",
    "most_useful_pos.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### During what hour of the day do most checkins occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkin.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|hour|   count|\n",
      "+----+--------+\n",
      "|null|18927198|\n",
      "|  19|   13481|\n",
      "|  23|   13207|\n",
      "|  22|   13191|\n",
      "|  18|   13177|\n",
      "|  21|   12960|\n",
      "|  20|   12553|\n",
      "|  17|   12304|\n",
      "|   0|   11577|\n",
      "|  16|   10416|\n",
      "|   1|    9803|\n",
      "|   2|    7258|\n",
      "|  15|    7000|\n",
      "|   3|    5225|\n",
      "|  14|    4340|\n",
      "|   4|    3547|\n",
      "|  13|    2910|\n",
      "|   5|    2348|\n",
      "|  12|    1597|\n",
      "|   6|    1450|\n",
      "|   7|    1020|\n",
      "|  11|     824|\n",
      "|   8|     809|\n",
      "|  10|     483|\n",
      "|   9|     470|\n",
      "+----+--------+\n",
      "\n",
      "CPU times: user 25.7 ms, sys: 8.02 ms, total: 33.7 ms\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import udf, explode\n",
    "from pyspark.sql.types import ArrayType,StringType\n",
    "from pyspark.sql.functions import hour, col\n",
    "\n",
    "datesplit = udf(lambda x: x.split(','),ArrayType(StringType()))\n",
    "\n",
    "checkin_hour = checkin.withColumn(\"date_exploded\", f.explode(datesplit(col(\"date\")))) \\\n",
    "                      .withColumn('hour', hour(col(\"date_exploded\"))) \\\n",
    "                      .groupby(['hour']).count().sort('count', ascending=False)\n",
    "\n",
    "checkin_hour.show(25) # show 24 hours + nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PySpark `hour` function used above generates null values because there are some spacing issues in the data. We will convert the string into an array, and group from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|hour|  count|\n",
      "+----+-------+\n",
      "|   0|1491176|\n",
      "|   1|1561788|\n",
      "|   2|1411255|\n",
      "|   3|1078939|\n",
      "|   4| 747453|\n",
      "|   5| 485129|\n",
      "|   6| 321764|\n",
      "|   7| 231417|\n",
      "|   8| 151065|\n",
      "|   9| 100568|\n",
      "|  10|  88486|\n",
      "|  11| 111769|\n",
      "|  12| 178910|\n",
      "|  13| 270145|\n",
      "|  14| 418340|\n",
      "|  15| 617830|\n",
      "|  16| 852076|\n",
      "|  17|1006102|\n",
      "|  18|1272108|\n",
      "|  19|1502271|\n",
      "|  20|1350195|\n",
      "|  21|1238808|\n",
      "|  22|1257437|\n",
      "|  23|1344117|\n",
      "+----+-------+\n",
      "\n",
      "CPU times: user 26.5 ms, sys: 2.14 ms, total: 28.7 ms\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "new_datesplit = udf(lambda x: int(x.split()[1].split(':')[0]), IntegerType())\n",
    "\n",
    "checkin_hour_v2 = checkin.withColumn(\"date_exploded\", f.explode(datesplit(col(\"date\")))) \\\n",
    "                         .withColumn(\"hour\", new_datesplit(col(\"date_exploded\"))) \\\n",
    "                         .groupby(['hour']).count() \\\n",
    "                         .sort('hour')\n",
    "\n",
    "checkin_hour_v2.show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additional udf adds a few seconds to the execution time, but for the additional value add it is worthwhile.\n",
    "\n",
    "#### Sentiment Analysis\n",
    "\n",
    "List the  50 most common non-stopword words that are unique to <i>positive</i> reviews, and 50 most common unique to <i>negative</i> reviews. We will consider `1` star as negative and `5` as positive.\n",
    "\n",
    "<b>Note:</b> There are some considerations here, such as embellishment and typos, but the data will be left as-is at this juncture so as to not assume intent of the writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import MapType \n",
    "\n",
    "def stop_word_cleaning(text):\n",
    "    STOPWORDS = {'i', 'we', 'ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', \n",
    "                 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', \n",
    "                 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', \n",
    "                 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', \n",
    "                 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', \n",
    "                 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', \n",
    "                 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', \n",
    "                 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', \n",
    "                 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', \n",
    "                 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', \n",
    "                 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', \n",
    "                 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it',\n",
    "                 'how', 'further', 'was', 'here', 'than'}\n",
    "    WORD_RE = re.compile(r\"[\\w']+\") \n",
    "\n",
    "    r_list = []\n",
    "    for word in WORD_RE.findall(text.lower()):\n",
    "        if word not in STOPWORDS:\n",
    "            r_list.append(word)\n",
    "            \n",
    "    return r_list\n",
    "\n",
    "stop_words_udf = udf(lambda x: stop_word_cleaning(x), ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_pos_data = review['stars','text'].filter(review['stars'] == 5)\n",
    "reduced_neg_data = review['stars','text'].filter(review['stars'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive word count\n",
    "pos_cnt = reduced_pos_data.withColumn('word', f.explode(stop_words_udf(col('text')))) \\\n",
    "                          .groupBy('word').count() \\\n",
    "                          .alias(\"pos_cnt\")\n",
    "\n",
    "# negative word count\n",
    "neg_cnt = reduced_neg_data.withColumn('word', f.explode(stop_words_udf(col('text')))) \\\n",
    "                          .groupBy('word').count() \\\n",
    "                          .alias(\"neg_cnt\")\n",
    "\n",
    "# Reduce computational time for overlapping words\n",
    "# intersections = pos_cnt.select('word').intersect(neg_cnt.select('word')).rdd.flatMap(lambda x:x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 50 positive words\n",
    "top_50_pos = pos_cnt.sort(col('count').desc(), ascending=False)#.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 50 negative words\n",
    "top_50_net = neg_cnt.sort(col('count').desc(), ascending=False)#.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of 12/2021, the `.show()` function is returning a Java error. Looking into this, as it may be a dependency or package version issue.\n",
    "\n",
    "Spun up this alternative solution in the meantime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------+\n",
      "|pos_neg|      word|wrd_cnt|\n",
      "+-------+----------+-------+\n",
      "|      +|     great|1336194|\n",
      "|      +|     place| 992555|\n",
      "|      +|      food| 830427|\n",
      "|      +|      good| 712097|\n",
      "|      +|       get| 691053|\n",
      "|      +|      like| 660552|\n",
      "|      +|      best| 648208|\n",
      "|      +|       one| 643653|\n",
      "|      +|      time| 640396|\n",
      "|      +|   service| 619802|\n",
      "|      +|      it's| 611242|\n",
      "|      +|      love| 602691|\n",
      "|      +|    always| 579908|\n",
      "|      +|    really| 573165|\n",
      "|      +|        go| 565067|\n",
      "|      +|     would| 555440|\n",
      "|      +|      also| 531716|\n",
      "|      +|      back| 515453|\n",
      "|      +|definitely| 479365|\n",
      "|      +|      i've| 475280|\n",
      "|      +|      even| 414864|\n",
      "|      +|     staff| 413054|\n",
      "|      +|       got| 411035|\n",
      "|      +| recommend| 407038|\n",
      "|      +|         -| 400456|\n",
      "|      +|       i'm| 382370|\n",
      "|      +|        us| 371761|\n",
      "|      +|  friendly| 362067|\n",
      "|      +|     first| 359682|\n",
      "|      +|      nice| 359092|\n",
      "|      +|      made| 347581|\n",
      "|      +|   amazing| 332412|\n",
      "|      +|      come| 331002|\n",
      "|      +|      make| 325404|\n",
      "|      +|       try| 323362|\n",
      "|      +|       new| 322151|\n",
      "|      +|     don't| 319905|\n",
      "|      +|      came| 319452|\n",
      "|      +|     every| 308296|\n",
      "|      +|everything| 306078|\n",
      "|      +|      went| 305379|\n",
      "|      +|     never| 298984|\n",
      "|      +|    little| 294246|\n",
      "|      +|         &| 286576|\n",
      "|      +|      well| 275363|\n",
      "|      +|     going| 270080|\n",
      "|      +|       it.| 265625|\n",
      "|      +|    highly| 265306|\n",
      "|      +|     could| 262239|\n",
      "|      +|      much| 260400|\n",
      "+-------+----------+-------+\n",
      "\n",
      "+-------+--------+-------+\n",
      "|pos_neg|    word|wrd_cnt|\n",
      "+-------+--------+-------+\n",
      "|      -|   would| 515916|\n",
      "|      -|     get| 493620|\n",
      "|      -|     one| 426422|\n",
      "|      -|    like| 397593|\n",
      "|      -|   never| 369781|\n",
      "|      -|    told| 359227|\n",
      "|      -|    even| 358690|\n",
      "|      -|    food| 356872|\n",
      "|      -|    back| 355463|\n",
      "|      -|   place| 348388|\n",
      "|      -|    said| 345998|\n",
      "|      -|    time| 345378|\n",
      "|      -| service| 327323|\n",
      "|      -|      go| 325977|\n",
      "|      -|   don't| 311146|\n",
      "|      -|      us| 307298|\n",
      "|      -|     got| 281475|\n",
      "|      -|  didn't| 280888|\n",
      "|      -|   asked| 259852|\n",
      "|      -|   could| 254312|\n",
      "|      -|    went| 245911|\n",
      "|      -|    came| 224592|\n",
      "|      -|    it's| 216166|\n",
      "|      -|  called| 196915|\n",
      "|      -|   going| 195427|\n",
      "|      -|   order| 193874|\n",
      "|      -|    good| 193269|\n",
      "|      -|customer| 192636|\n",
      "|      -|  people| 191198|\n",
      "|      -|     i'm| 189199|\n",
      "|      -| another| 187447|\n",
      "|      -| minutes| 186215|\n",
      "|      -|   first| 181967|\n",
      "|      -|    know| 180303|\n",
      "|      -|    took| 176248|\n",
      "|      -| ordered| 175198|\n",
      "|      -|    take| 173543|\n",
      "|      -|    come| 172543|\n",
      "|      -|    give| 170697|\n",
      "|      -|   still| 164457|\n",
      "|      -|    make| 160990|\n",
      "|      -|  really| 158439|\n",
      "|      -|     it.| 158202|\n",
      "|      -|     two| 154178|\n",
      "|      -|    call| 153347|\n",
      "|      -|       -| 151486|\n",
      "|      -|    want| 148615|\n",
      "|      -|     car| 147982|\n",
      "|      -|    ever| 147483|\n",
      "|      -|       2| 146254|\n",
      "+-------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "STOPWORDS = {'i', 'we', 'ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than'}\n",
    "\n",
    "# Define UDFs for use in the analysis\n",
    "# For this exercise, for now, we will consider 3+ stars as \"positive\" and 1 or 2 stars as negative.\n",
    "review_type = udf(lambda x: '+' if (x >= 5.0) else ('-' if (x <= 1.0) else 'Neutral'),StringType())\n",
    "rev_wrd_lst = udf(lambda x: [w.lower() for w in x.split() if w.lower() not in STOPWORDS], ArrayType(StringType()))\n",
    "\n",
    "# Create columns assigning positive and negative sentiment, as well as\n",
    "# a list of words contained in the text that excludes stopwords\n",
    "rev = review.select('review_id', review_type('stars').alias('pos_neg'), rev_wrd_lst('text').alias('words'))\n",
    "#rev = spark.createDataFrame(rev) # Sometimes this is required to run without errors, sometimes it is not.... ?\n",
    "\n",
    "# Explode so each word gets its own row and retains its assignment of positive and negative.\n",
    "rev = rev.withColumn('word',explode('words'))\n",
    "\n",
    "# Groupby sentiment and word, with an aggregate count of the word's use.\n",
    "v2 = rev.groupby(['pos_neg','word']).agg(f.count('word').alias('wrd_cnt'))\n",
    "\n",
    "# Create separate list for positive sentiment\n",
    "v2_pos = v2.filter(v2['pos_neg'] == '+').sort(col('wrd_cnt').desc()).head(50)\n",
    "v2_pos = spark.createDataFrame(v2_pos)\n",
    "\n",
    "# Create separate list for negative sentiment\n",
    "v2_neg = v2.filter(v2['pos_neg'] == '-').sort(col('wrd_cnt').desc()).head(50)\n",
    "v2_neg = spark.createDataFrame(v2_neg)\n",
    "\n",
    "# Show dataframes\n",
    "v2_pos.show(50)\n",
    "v2_neg.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________\n",
    "<div style=\"text-align: right\"><sub>Exercise adapted and modified from UMSI homework assignment for SIADS 516.</sub></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
